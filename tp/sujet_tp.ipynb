{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP: Essaims de nano-satellites -- *Nanosatellite swarms*\n",
    "\n",
    "Ce TP a pour objectif de vous familiariser davantage avec les topologies d'essaims de nano-satellites en exploitant un jeu de données. Vous verrez notamment qu'on peut extraire énormément d'informations à partir d'un jeu de données simple (ici, positions des satellites par pas de temps). Le TP se déroule en 3 parties :  \n",
    "\n",
    "1. Chargement des données : découverte du jeu de données et formattage pour la suite\n",
    "2. Visualisation de la topologie\n",
    "3. Partage de charge : division en sous-réseaux\n",
    "\n",
    "Nous allons d'abord importer les librairies nécessaires, dont le module de simulation `swarm_sim` disponible dans le dossier `\\tp`.  \n",
    "\n",
    "***\n",
    "\n",
    "*The objective of this TP is to become familiar with nanosatellite swarms topologies extracted from a given dataset. You'll notice in particular that one can extract a lot of information from a rather simple dataset (here, temporal satellite positions). This TP is divided in 3 parts:*  \n",
    "\n",
    "1.  *Data loading: dataset exploration and initialization*\n",
    "2.  *Visualization of the topologies*\n",
    "3.  *Data load balancing: division into sub-networks*  \n",
    "\n",
    "*We will first import and the necessary Python libraries, namely the simulation module* `swarm_sim` *that you can find under the* `\\tp` *directory.*  \n",
    "\n",
    "*Make sure you choose the* `.venv` *environment for execution.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from swarm_sim import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des données -- *Data loading*\n",
    "\n",
    "Les données sont stockées dans le dossier `\\data\\swarm-50-sats-scenario` du repository Git, et sont réparties en 50 traces de nano-satellites échantillonnées sur 24 heures.  \n",
    "\n",
    "Ouvrez une trace en exécutant la cellule suivante, et rappelez les champs ainsi que les unités utilisées (n'hésitez pas à revoir le cours, slide 20).\n",
    "\n",
    "***\n",
    "\n",
    "*The dataset is available under the* `\\data\\swarm-50-sats-scenario` *folder of the Git repository. It consists of 50 separate nanosatellite tracks sampled over 24 hours.*  \n",
    "\n",
    "*Open one track by executing the following cell, and pay attention to the fields and units (slide 35).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '..\\\\data\\\\swarm-50-sats-scenario\\\\coords_v1_if_LLO-' #You might need to adapt, depending on the OS\n",
    "NB_NODES = 50\n",
    "DURATION = 8641 # Number of data samples, not time!\n",
    "REVOLUTION = 1800 # Number of data rows to complete a revolution around the Moon\n",
    "CONNECTION_RANGE = 30 # km\n",
    "\n",
    "row_metadata_end = 6\n",
    "row_data_start = 7\n",
    "\n",
    "sat_id = 0\n",
    "df_metadata = pd.read_csv(PATH+str(sat_id)+'.csv', skiprows = lambda x: x>row_metadata_end)\n",
    "df_data = pd.read_csv(PATH+str(sat_id)+'.csv', skiprows= lambda x: x<row_data_start, header=0)\n",
    "        \n",
    "print(df_metadata)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargez la totalité des données dans ce notebook. Nous allons créer un dictionnaire contenant ces données suivant ce format : \n",
    "\n",
    "`satellites[id] = track`\n",
    "\n",
    "Modifiez la variable `PATH` si nécessaire.\n",
    "\n",
    "NB : le chargement peut être assez long (plusieurs minutes en fonction de la machine). Vous pouvez visualiser la progression du chargement avec la fonction `tqdm()`.  \n",
    "\n",
    "***\n",
    "\n",
    "*You can now load the whole dataset into a Python dictionary formatted as follows:*  \n",
    "\n",
    "`satellites[id] = track`  \n",
    "\n",
    "*Modify the* `PATH` *variable if necessary.*  \n",
    "\n",
    "*NB: the loading can take some time (sometimes a couple minutes, depending on the machine). You can visualize the progression of the loading with the* `tqdm()` *function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {}\n",
    "satellites = {}\n",
    "\n",
    "with tqdm(total=NB_NODES, desc='Extracting data') as pbar:\n",
    "    for i in range(NB_NODES):\n",
    "        df_metadata = pd.read_csv(PATH+str(i)+'.csv', skiprows = lambda x: x>row_metadata_end)\n",
    "        metadata[i] = df_metadata\n",
    "        df_data = pd.read_csv(PATH+str(i)+'.csv', skiprows= lambda x: x<row_data_start, header=0)\n",
    "        satellites[i] = df_data\n",
    "        pbar.update(1)\n",
    "        \n",
    "satellites[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de faciliter la suite du traitement, nous allons créer un objet `Swarm` tel que défini dans le module `swarm_sim` par pas de temps et les stocker dans un dictionnaire tel que :\n",
    "\n",
    "`swarm_data[timestamp] = Swarm`\n",
    "\n",
    "N'hésitez pas à lire la doc pour le formattage en objet `Swarm`.  \n",
    "\n",
    "***\n",
    "\n",
    "*In order to simplify the following data analysis, we will create* `Swarm` *objects as defined in the* `swarm_sim` *module for each timestamp, and stock them in a dictionary such as:*  \n",
    "\n",
    "`swarm_data[timestamp] = Swarm`\n",
    "\n",
    "*Don't hesitate to take a look at the documentation to understand the formatting process.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Swarm.__init__)\n",
    "help(Node.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm_data = {}\n",
    "\n",
    "with tqdm(total=DURATION, desc='Converting to Swarm') as pbar:\n",
    "    for t in range(DURATION):\n",
    "        swarm_data[t] = Swarm(connection_range=CONNECTION_RANGE,\n",
    "                    nodes = [Node(id, sat['xF[km]'].iloc[t], sat['yF[km]'].iloc[t], sat['zF[km]'].iloc[t]) for id,sat in satellites.items()]\n",
    "                    )\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez le contenu du `swarm_data` à l'instant `0`, ainsi que la description d'un noeud de votre choix. Assurez-vous de bien comprendre tous les champs affichés.  \n",
    "\n",
    "***\n",
    "\n",
    "*Print the content of* `swarm_data` *at timestamp* `0`*, as well as the description of a node of your choosing. Make sure you understand all the fields.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm = swarm_data[0]\n",
    "\n",
    "# To do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualisation de la topologie -- *Topology visualization*  \n",
    "\n",
    "Le module `swarm_sim` permet notamment de créer des graphiques 3D représentant les positions des satellites à un instant donné, avec si besoin les ISL (liens inter-satellites) existants. Il s'agit des fonctions `plot_nodes()` et `plot_edges()`.  \n",
    "\n",
    "Affichez la topologie de l'essaim à un pas de temps donné, puis à un autre.  \n",
    "\n",
    "Qu'observez-vous au niveau de la topologie ?  \n",
    "\n",
    "***\n",
    "\n",
    "*The* `swarm_sim` *module allows you to create 3D graphs representing the positions of the nanosatellites at a given time, and if needed, the existing ISL (inter-satellite links). To do so, you can use the functions* `plot_nodes()` *and* `plot_edges()`.  \n",
    "\n",
    "*Display the swarm topology at a given time (you choose), then at another further away.*  \n",
    "\n",
    "*What do you observe on the topologies?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm_data[0].plot_nodes()\n",
    "swarm_data[0].plot_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous avez sûrement remarqué que la fonction `plot_edges()` ne fonctionne pas, ou du moins elle n'affiche aucune connexion dans l'essaim. Pourquoi ?  \n",
    "\n",
    "***\n",
    "\n",
    "*You probably noticed that* `plot_edges()` *doesn't actually return any edge. Why so?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Réponse -- answer\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etablissez les connexions entre noeuds voisins grâce à la fonction `neighbor_matrix()` (regardez la doc pour comprendre comment elle fonctionne), puis affichez la topologie de l'essaim grâce à la fonction `plot_edges()`.  \n",
    "\n",
    "***\n",
    "\n",
    "*Establish the connections between neighbor nodes with the function* `neighbor_matrix()` *(take a look at the doc to understand how it works), then display the swarm topology with* `plot_edges()`*.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Swarm.neighbor_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(total=DURATION, desc='Neighbor matrix') as pbar:\n",
    "    for t in range(DURATION):\n",
    "        neighbor_matrix = swarm_data[t].neighbor_matrix()\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm_data[0].plot_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Partage de charge -- *Load balancing*\n",
    "\n",
    "Nous allons maintenant nous intéresser à la gestion de la redondance et du recouvrement dans le réseau (slides 29+ du cours).\n",
    "\n",
    "Pour rappel, lors d'une mission d'interférométrie, chaque nanosatellite va collecter près de 5 Gb de données brutes de l'espace. Afin de créer l'image globale collectée par l'essaim, toutes les données collectées doivent être échangées entre l'intégralité des satellites. Sans politique de limitation de recouvrement, le réseau va saturer très vite.\n",
    "\n",
    "Afin de limiter ce recouvrement, une solution est de diviser le réseau en plusieurs sous-réseaux grâce à des algorithmes de **division de graphe**. En effet, les sous-réseaux obtenus vont faire office de \"noeuds\" dans le graphe simplifié, et on va ainsi limiter la quantité de données échangées simultanément. Nous allons analyser les performances de trois algorithmes: **Random Node Division** (`RND`), **Multiple Independent Random Walk** (`MIRW`) et **Forest Fire Division** (`FFD`).\n",
    "\n",
    "Cherchez les fonctions correspondantes à ces algorithmes dans la doc, et assurez-vous de bien comprendre leur principe de fonctionnement. Quelles sont les différences majeures dans leur implémentation ?  \n",
    "\n",
    "***\n",
    "\n",
    "*We will now focus on the redundancy management and network overload control (slides 27+).*  \n",
    "\n",
    "*Reminder: during an interferometry mission, each nanosatellite collects approx. 5 Gb of space observation raw data. IN order to create the global image collected by the swarm, all data packets need to be shared among all the satellites of the swarm. Without overload control, the network will experience strong congestion.*  \n",
    "\n",
    "*In order to manage the data overload, one solution is to divide the network into sub-networks by using* **Graph Division** *algorithms. The resulting sub-networks can indeed act as big aggregated nodes in a simplified version of the graph, and thus limit the amount of data to transmit. We will analyze the performance of 3 division algorithms:* **Random Node Division** (`RND`), **Multiple Independent Random Walk** (`MIRW`) *and* **Forest Fire Division** (`FFD`).  \n",
    "\n",
    "*Look for these algorithms in the documentation and take a look at how they operate. What are the main differences in their respective implementations?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Swarm.RND) # Test with MIRW and FFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Réponse -- answer\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prenez un essaim à un instant `T` et appliquez-lui d'abord l'algorithme `RND`. Paramétrez-le de sorte à obtenir `5` groupes.  \n",
    "\n",
    "***\n",
    "\n",
    "*Take a swarm at a given time* `T` *and start by applying the* `RND` *algorithm. Configure it to obtain a division into* `5` *groups.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 0\n",
    "NB_GROUPS = 1\n",
    "swarm = swarm_data[T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It's a good practice to reset the swarm division to its default value before starting (-1)\n",
    "swarm.reset_groups() \n",
    "swarms_rnd = swarm.RND(n=NB_GROUPS)\n",
    "\n",
    "for i,sw in swarms_rnd.items():\n",
    "    print(sw)\n",
    "    print([n.id for n in sw.nodes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faites maintenant la même chose mais avec l'algorithme `MIRW` afin d'obtenir une autre répartition.  \n",
    "\n",
    "***\n",
    "\n",
    "*Now do the same with the* `MIRW` *algorithm in order to obtain a different distribution.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Swarm.MIRW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm.reset_groups()\n",
    "swarms_mirw = swarm.MIRW(n=NB_GROUPS) \n",
    "\n",
    "for i,sw in swarms_mirw.items():\n",
    "    print(sw)\n",
    "    print([n.id for n in sw.nodes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, obtenez une troisième répartition grâce à l'algorithme `FFD`.  \n",
    "\n",
    "***\n",
    "\n",
    "*Finally, get one last repartition with* `FFD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Swarm.FFD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm.reset_groups()\n",
    "swarms_ffd = swarm.FFD(n=NB_GROUPS)\n",
    "\n",
    "for i,sw in swarms_ffd.items():\n",
    "    print(sw)\n",
    "    print([n.id for n in sw.nodes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A présent, nous allons comparer ces algorithmes en fonction de la répartition de la **taille des groupes** obtenus, l'idéal étant d'obtenir la répartition la plus homogène possible.\n",
    "\n",
    "Exécutez les cellules suivantes afin de générer les graphiques correspondant aux répartitions des trois algorithmes. Adaptez le nom des variables si besoin.  \n",
    "\n",
    "***\n",
    "\n",
    "*We will now compare the performance of these 3 algorithms on the distribution of the* **group size**. *The objective is to obtain the fairest distribution of group sizes.*  \n",
    "\n",
    "*Execute the following cells to generate figures corresponding to the group size distribution of each algorithm. Adapt the variable names if necessary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distrib_rnd = [len(sw.nodes) for sw in swarms_rnd.values()] # Group size distribution\n",
    "distrib_mirw = [len(sw.nodes) for sw in swarms_mirw.values()]\n",
    "distrib_ffd = [len(sw.nodes) for sw in swarms_ffd.values()]\n",
    "\n",
    "values = [] # Variable used to compare all distributions on the same scale\n",
    "values.extend(distrib_rnd)\n",
    "values.extend(distrib_mirw)\n",
    "values.extend(distrib_ffd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(set(values))\n",
    "x_pos = np.arange(min(labels), max(labels)+1)\n",
    "data_rnd, data_mirw, data_ffd = [], [], []\n",
    "for k in x_pos:\n",
    "       a,b,c = 0,0,0\n",
    "       if k in distrib_rnd:\n",
    "            a = len([e for e in distrib_rnd if e==k])\n",
    "       data_rnd.append(a)\n",
    "       if k in distrib_mirw:\n",
    "            b = len([e for e in distrib_mirw if e==k])\n",
    "       data_mirw.append(b)\n",
    "       if k in distrib_ffd:\n",
    "            c = len([e for e in distrib_ffd if e==k])\n",
    "       data_ffd.append(c)\n",
    "\n",
    "# Figure generation\n",
    "fig, axes = plt.subplots(nrows=3, figsize=(12,12))\n",
    "ax = axes[0] # Histogramme RND\n",
    "ax.bar(x_pos, data_rnd,\n",
    "       align='center',\n",
    "       alpha=0.5)\n",
    "ax.set_ylabel('# Occurrences')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(x_pos)\n",
    "ax.set_ylim(0, NB_GROUPS)\n",
    "ax.set_title('RND distribution')\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "ax = axes[1] # Histogramme MIRW \n",
    "ax.bar(x_pos, data_mirw,\n",
    "       align='center',\n",
    "       alpha=0.5)\n",
    "ax.set_ylabel('# Occurrences')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(x_pos)\n",
    "ax.set_ylim(0, NB_GROUPS)\n",
    "ax.set_title('MIRW distribution')\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "ax = axes[2] # Histogramme FFD \n",
    "ax.bar(x_pos, data_ffd,\n",
    "       align='center',\n",
    "       alpha=0.5)\n",
    "ax.set_xlabel('# Nodes in group')\n",
    "ax.set_ylabel('# Occurrences')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(x_pos)\n",
    "ax.set_ylim(0, NB_GROUPS)\n",
    "ax.set_title('FFD distribution')\n",
    "ax.yaxis.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, nous avons effectué une division à `10%` (5 groupes). Quel algorithme semble le plus adapté dans ce cas ? Le moins adapté ? Pourquoi ?  \n",
    "\n",
    "***\n",
    "\n",
    "*Here, we have performed a* `10%`*-division (5 groups). Which algorithm seems to be the best fitted in your opinion? Why so?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Réponse -- answer\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Répétez les opérations précédentes, mais cette fois-ci en effectuant une division en **2**, **7** puis **10** groupes.  \n",
    "\n",
    "NB : pour être rigoureux, il faudrait répéter chaque expérience un grand nombre de fois, car les 3 algorithmes se basent sur de l'aléatoire (d'où le paramètre \"seed\" dans les fonctions). Si cela est trop long à réaliser, vous pouvez choisir des seeds différentes de vos voisins afin de confronter vos résultats.  \n",
    "\n",
    "***\n",
    "\n",
    "*Repeat the previous operation, but now divide the swarm respectively into* **2**, **7** *and* **10** *groups.*  \n",
    "\n",
    "*NB: because all 3 algorithms are based on random processes (the \"seed\" parameter), you should repeat each operation at least 30 times to get a rigorous and reliable result. It would probably take too long to do that, so instead you can simply choose different seeds from your classmates, then compare your results.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A faire -- To do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'après vos résultats et ceux de vos voisins, comment évolue la performance des algorithmes lorsqu'on augmente le nombre de groupes ? Qu'en concluez-vous sur la performance globale de ces algorithmes sur la division d'un essaim de nanosatellites ?  \n",
    "\n",
    "***\n",
    "\n",
    "*From your results and those of the class, how do the algorithms perform when you vary the group size? What can you conclude on the overall performance of these algorithms on the graph division of a nanosatellite swarm?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Réponse -- answer\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour aller plus loin : estimation de la charge réseau -- Network load estimation\n",
    "\n",
    "Comme énoncé dans le cours (slides 31-32), la division en groupes a un fort impact sur le nombre de paquets de données à émettre dans l'essaim. La charge du réseau est estimée par la fonction `network_load()` définie ci-dessous, et est égale à la somme des paquets à échanger au sein du groupe (`total_intra`) et avec les autres groupes (`total_inter`).\n",
    "\n",
    "Cette fonction considère 2 cas :\n",
    " * situation d'équité (`fair = True`) : les noeuds sont répartis équitablement au sein des groupes\n",
    " * situation de non-équité : le nombre de noeuds varie en fonction du groupe.\n",
    "\n",
    " Compléter cette fonction afin de considérer le 2e cas.  \n",
    "\n",
    " ***\n",
    "\n",
    "*As stated during the lecture (slide 29), graph division has an important impact on the number of data packets to transmit within the swarm. The network load is estimated by the function* `network_load()` *defined below, and is equal to the sum of packets to transmit within the group* (`total_intra`) *and with the other groups* (`total_inter`).  \n",
    "\n",
    "*This function considers 2 cases:*  \n",
    "* *the division is fair* (`fair = True`): *the nodes are fairly distributed among the groups*\n",
    "* *the division is not fair: the number of nodes varies with the groups.*\n",
    "\n",
    "*Complete this function in order to consider the 2nd case.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_load(swarm, nb_groups, fair=True):\n",
    "    total_nodes = len(swarm.nodes)\n",
    "    \n",
    "    if fair:    \n",
    "        nodes_per_group = total_nodes/nb_groups\n",
    "        total_intra = nb_groups * nodes_per_group*(nodes_per_group-1)\n",
    "    else:\n",
    "        # To complete (remove 'pass' when you're done!)\n",
    "        pass\n",
    "    \n",
    "    total_inter = nb_groups*(nb_groups-1)  # Don't change\n",
    "    net_load = total_intra+total_inter\n",
    "    print('Network load:', net_load, 'packets.')\n",
    "    return net_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testez cette fonction sur la topologie (divisée) de votre choix : calculez le nombre de paquets à transmettre relatif à la division de graphe en situation réelle et en situation d'équité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A faire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut assez vite comprendre pourquoi on cherche à effectuer une division équitable !\n",
    "\n",
    "***\n",
    "\n",
    "*You can easily see why we want a fair division!*  \n",
    "*Congrats, you've made it this far.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2ac6d069bff998233dee9bcdfa94e87e94bde565510066770655f86bcf93c541"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
